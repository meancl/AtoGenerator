{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6e663b-eb93-4ebb-9fbb-4c3eba485bdc",
   "metadata": {},
   "source": [
    "# 데이터 획득 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990c0fc-a349-4d91-a368-f5d2724d69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24889c-cf5c-4f89-b1f7-407161d64f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql://sbe03253:jin94099@database-2.clmg3ftdxi2a.ap-northeast-2.rds.amazonaws.com/MJTradierDB')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f5ada-4527-4303-964c-bfde92289b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = db.MetaData()\n",
    "table = db.Table('scaleDatasDict', metadata, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018ef0d-c74d-49a2-ae99-c6aad87e79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = pd.read_sql_table('buyReports', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608fa50-6218-4185-ae8c-f388886a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "br = br[( br['isAllBuyed'] == 1) & ( br['isAllSelled'] == 1) & (br['nBuyVolume'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e94819-45cb-4aa1-839f-5b7efa098597",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names =  [   \n",
    "        'nBuyStrategyIdx',\n",
    "        'nRqTime' , \n",
    "        'fStartGap' ,\n",
    "        'fPowerWithOutGap' , \n",
    "        'fPower' , \n",
    "        'fPlusCnt07' , \n",
    "        'fMinusCnt07' , \n",
    "        'fPlusCnt09' , \n",
    "        'fMinusCnt09' ,\n",
    "        'fPowerJar' , \n",
    "        'fOnlyDownPowerJar' , \n",
    "        'fOnlyUpPowerJar' , \n",
    "        'nTradeCnt' , \n",
    "        'nChegyulCnt' , \n",
    "        'nHogaCnt' , \n",
    "        'nNoMoveCnt' , \n",
    "        'nFewSpeedCnt' ,\n",
    "        'nMissCnt' , \n",
    "        'lTotalTradeVolume' , \n",
    "        'lTotalBuyVolume' , \n",
    "        'lTotalSellVolume' ,\n",
    "        'nAccumUpDownCount' ,\n",
    "        'fAccumUpPower' , \n",
    "        'fAccumDownPower' ,\n",
    "        'lTotalTradePrice' , \n",
    "        'lTotalBuyPrice' , \n",
    "        'lTotalSellPrice' , \n",
    "        'lMarketCap' , \n",
    "        'nAccumCountRanking' , \n",
    "        'nMarketCapRanking' , \n",
    "        'nPowerRanking' , \n",
    "        'nTotalBuyPriceRanking' , \n",
    "        'nTotalBuyVolumeRanking' ,\n",
    "        'nTotalTradePriceRanking' ,\n",
    "        'nTotalTradeVolumeRanking' ,\n",
    "        'nTotalRank' , \n",
    "        'nMinuteTotalRank' , \n",
    "        'nMinuteTradePriceRanking' ,\n",
    "        'nMinuteTradeVolumeRanking' , \n",
    "        'nMinuteBuyPriceRanking' , \n",
    "        'nMinuteBuyVolumeRanking' ,\n",
    "        'nMinutePowerRanking' , \n",
    "        'nMinuteCountRanking' ,\n",
    "        'nMinuteUpDownRanking' ,\n",
    "        'nFakeBuyCnt' , \n",
    "        'nFakeAssistantCnt' ,\n",
    "        'nFakeResistCnt' , \n",
    "        'nPriceUpCnt' , \n",
    "        'nPriceDownCnt' ,\n",
    "        'nTotalFakeCnt' ,\n",
    "        'nTotalFakeMinuteCnt' ,\n",
    "        'nUpCandleCnt' , \n",
    "        'nDownCandleCnt' ,\n",
    "        'nUpTailCnt' , \n",
    "        'nDownTailCnt' ,\n",
    "        'nShootingCnt' ,\n",
    "        'nCandleTwoOverRealCnt' ,\n",
    "        'nCandleTwoOverRealNoLeafCnt' , \n",
    "        'fSpeedCur' , \n",
    "        'fHogaSpeedCur' ,\n",
    "        'fTradeCur' , \n",
    "        'fPureTradeCur' , \n",
    "        'fPureBuyCur' , \n",
    "        'fHogaRatioCur' ,  \n",
    "        'fSharePerHoga' , \n",
    "        'fSharePerTrade' ,\n",
    "        'fHogaPerTrade' , \n",
    "        'fTradePerPure' , \n",
    "        'fMaDownFsVal' , \n",
    "        'fMa20mVal' , \n",
    "        'fMa1hVal' ,\n",
    "        'fMa2hVal' ,\n",
    "        'fMaxMaDownFsVal' ,\n",
    "        'fMaxMa20mVal' ,\n",
    "        'fMaxMa1hVal' ,\n",
    "        'fMaxMa2hVal' ,\n",
    "        'nMaxMaDownFsTime' ,\n",
    "        'nMaxMa20mTime' ,\n",
    "        'nMaxMa1hTime' ,\n",
    "        'nMaxMa2hTime' ,\n",
    "        'nDownCntMa20m' ,\n",
    "        'nDownCntMa1h' ,\n",
    "        'nDownCntMa2h' ,\n",
    "        'nUpCntMa20m' ,\n",
    "        'nUpCntMa1h' ,\n",
    "        'nUpCntMa2h' ,\n",
    "        'fMSlope' ,\n",
    "        'fISlope' ,\n",
    "        'fTSlope' ,\n",
    "        'fHSlope' ,\n",
    "        'fRSlope' ,\n",
    "        'fDSlope' ,\n",
    "        'fMAngle' ,\n",
    "        'fIAngle' ,\n",
    "        'fTAngle' ,\n",
    "        'fHAngle' ,\n",
    "        'fRAngle' ,\n",
    "        'fDAngle' ,\n",
    "        'nCrushCnt' ,\n",
    "        'nCrushUpCnt' ,\n",
    "        'nCrushDownCnt' ,\n",
    "        'nCrushSpecialDownCnt' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47e039-04cf-4368-b596-9ed7f16284e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "X = br[\n",
    "   feature_names\n",
    "]\n",
    "MINMAX = 'MinMax'\n",
    "ROBUST = 'Robust'\n",
    "STANDARD = 'Standard'\n",
    "\n",
    "scale_method = ROBUST\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "print(type(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11937a4-0ba5-46b8-8b8a-a936a3d6f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "y = br['fProfit'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8010c47-713d-47e8-a665-9bc814c1c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98022fe4-374b-472c-b543-c1064dc11c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbe567-cf95-4ee3-9978-57ac87f12f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputDim = 102\n",
    "nOutputDim = 1\n",
    "main_input = Input(shape=(nInputDim), name='input')\n",
    "x = Dense(256, activation='relu')(main_input)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Regression\n",
    "main_output = Dense(nOutputDim, name='output')(x)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=main_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6123610-16c0-471a-be51-1ea74b6fe506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "istory = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f770e-c62b-4e7a-a0be-f6b70f621b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('accuracy : ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6726e-720b-4401-bfbd-0e8c61d46145",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4e950-3d42-45e8-8c22-b07951b97897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(y_pred.shape[0]):\n",
    "#     print(y_pred[i], '  , ', y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2ee67-1520-450a-aea0-fb011875e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = 0\n",
    "fl = 0\n",
    "\n",
    "d_ac = 0\n",
    "d_fl = 0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_pred[i] > 0.01:\n",
    "        if(y_test[i] > 0.01):\n",
    "            ac += 1\n",
    "        else:\n",
    "            fl += 1\n",
    "            \n",
    "    if y_pred[i] < 0.01:\n",
    "        if(y_test[i] < 0.01):\n",
    "            d_ac += 1\n",
    "        else:\n",
    "            d_fl += 1\n",
    "    #print(i, '  pred : ' , y_pred[i], ' test : ' , y_test[i])\n",
    "\n",
    "print('============ (-) =============')\n",
    "print('d_sum : ', d_ac+ d_fl)\n",
    "print('d_  ', d_ac, ' and ', d_fl)\n",
    "print('d_ratio : ', d_ac / (d_ac+d_fl), end='\\n\\n')\n",
    "    \n",
    "print('============ (+) =============')\n",
    "print('sum : ', ac+ fl)\n",
    "print(ac, ' and ', fl)\n",
    "print('ratio : ', ac / (ac+fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b5f79-3279-4a5c-84b3-0c0d09986a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'fProfit_10_Robust_r'\n",
    "h5_path = './h5/'\n",
    "onnx_path = './onnx/'\n",
    "tmp_model_path = './model_tmp/'\n",
    "save_model_name = model_name +'.h5'\n",
    "output_onnx_file_name = model_name + '.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a686fe3-bee2-4e92-a31d-8723efaa25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(h5_path + save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1b682-b996-4ca2-a01c-43a600260aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# h5 to pb\n",
    "model_convert = tf.keras.models.load_model(h5_path + save_model_name, compile=False)\n",
    "model_convert.save(tmp_model_path, save_format=\"tf\")\n",
    "\n",
    "# pb to onnx \n",
    "import os\n",
    "os.system('python -m tf2onnx.convert --saved-model ' +  tmp_model_path + ' --output ' + onnx_path + output_onnx_file_name + ' --opset 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f424225-98c3-4d9c-b758-d99922d208c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteScaleData(table, feature_names, scale_method, model_name, pandas_data ):\n",
    "    try:\n",
    "        today = datetime.datetime.today()\n",
    "        scaleMethod = scale_method\n",
    "        sModel = model_name\n",
    "        fD0 = None\n",
    "        fD1 = None\n",
    "        fD2 = None\n",
    "\n",
    "        for idx, col in enumerate(feature_names):\n",
    "            sVar = col\n",
    "            if scale_method == 'MinMax': # MinMax Scaler\n",
    "                fD0 = pandas_data[col].min()\n",
    "                fD1 = pandas_data[col].max()\n",
    "                fD2 = fD0\n",
    "            elif scale_method == 'Standard': # Standard Scaler\n",
    "                fD0 = pandas_data[col].mean()\n",
    "                fD1 = pandas_data[col].std()\n",
    "                fD2 = 0\n",
    "            elif scale_method == 'Robust' : # Robust Scaler\n",
    "                fD0 = pandas_data[col].median()\n",
    "                fD1 = pandas_data[col].quantile(q= 0.75)\n",
    "                fD2 = pandas_data[col].quantile(q= 0.25)\n",
    "            else :\n",
    "                raise Exception('Threr is no suitable scaler method')\n",
    "\n",
    "            query = db.insert(table).values( {'dTime': today, 'sScaleMethod':scaleMethod, 'sVariableName':sVar, \n",
    "                            'sModelName':sModel, 'fD0':fD0, 'fD1':fD1, 'fD2':fD2, 'nSeq':idx})\n",
    "            result_proxy = conn.execute(query)\n",
    "            result_proxy.close()\n",
    "        print('put scale to ', sModel, ' ends')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return;\n",
    "\n",
    "\n",
    "WriteScaleData(table=table, feature_names=feature_names, scale_method=scale_method,\n",
    " model_name=output_onnx_file_name, pandas_data=br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57adbb05-c622-4231-b921-27de38105185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
