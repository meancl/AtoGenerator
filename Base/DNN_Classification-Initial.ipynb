{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6e663b-eb93-4ebb-9fbb-4c3eba485bdc",
   "metadata": {},
   "source": [
    "# 데이터 획득 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bcfaad-d80d-44d2-b1e7-4c4f5a6fa529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c26b1e-7965-4ca9-9ec9-d91d05ce8ac6",
   "metadata": {},
   "source": [
    "# DB 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc24889c-cf5c-4f89-b1f7-407161d64f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql://sbe03253:jin94099@database-2.clmg3ftdxi2a.ap-northeast-2.rds.amazonaws.com/MJTradierDB')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d530b36-c19c-449c-bde3-df77fb70cde2",
   "metadata": {},
   "source": [
    "# 테이블 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8801b92f-451c-4356-8ace-75599e939d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_full_data = pd.read_sql_table('buyReports', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f7d66-f3e3-4d3f-83b0-58a397461106",
   "metadata": {},
   "source": [
    "# 학습에 사용할 데이터 필터링 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6608fa50-6218-4185-ae8c-f388886a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "get_filter = ( br_full_data['isAllBuyed'] == 1) & ( br_full_data['isAllSelled'] == 1) & (br_full_data['nBuyVolume'] > 0)\n",
    "extract_filter = (br_full_data['dTradeTime'] >= datetime.datetime(2023, 2, 16))\n",
    "br = br_full_data[get_filter & ~extract_filter]\n",
    "br_extract = br_full_data[extract_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f23acce-e837-4f74-9c1c-b8687fcd1175",
   "metadata": {},
   "source": [
    "# 피처변수 컬럼명 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e94819-45cb-4aa1-839f-5b7efa098597",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_102 =  [   \n",
    "        'nBuyStrategyIdx',\n",
    "        'nRqTime' , \n",
    "        'fStartGap' ,\n",
    "        'fPowerWithOutGap' , \n",
    "        'fPower' , \n",
    "        'fPlusCnt07' , \n",
    "        'fMinusCnt07' , \n",
    "        'fPlusCnt09' , \n",
    "        'fMinusCnt09' ,\n",
    "        'fPowerJar' , \n",
    "        'fOnlyDownPowerJar' , \n",
    "        'fOnlyUpPowerJar' , \n",
    "        'nTradeCnt' , \n",
    "        'nChegyulCnt' , \n",
    "        'nHogaCnt' , \n",
    "        'nNoMoveCnt' , \n",
    "        'nFewSpeedCnt' ,\n",
    "        'nMissCnt' , \n",
    "        'lTotalTradeVolume' , \n",
    "        'lTotalBuyVolume' , \n",
    "        'lTotalSellVolume' ,\n",
    "        'nAccumUpDownCount' ,\n",
    "        'fAccumUpPower' , \n",
    "        'fAccumDownPower' ,\n",
    "        'lTotalTradePrice' , \n",
    "        'lTotalBuyPrice' , \n",
    "        'lTotalSellPrice' , \n",
    "        'lMarketCap' , \n",
    "        'nAccumCountRanking' , \n",
    "        'nMarketCapRanking' , \n",
    "        'nPowerRanking' , \n",
    "        'nTotalBuyPriceRanking' , \n",
    "        'nTotalBuyVolumeRanking' ,\n",
    "        'nTotalTradePriceRanking' ,\n",
    "        'nTotalTradeVolumeRanking' ,\n",
    "        'nTotalRank' , \n",
    "        'nMinuteTotalRank' , \n",
    "        'nMinuteTradePriceRanking' ,\n",
    "        'nMinuteTradeVolumeRanking' , \n",
    "        'nMinuteBuyPriceRanking' , \n",
    "        'nMinuteBuyVolumeRanking' ,\n",
    "        'nMinutePowerRanking' , \n",
    "        'nMinuteCountRanking' ,\n",
    "        'nMinuteUpDownRanking' ,\n",
    "        'nFakeBuyCnt' , \n",
    "        'nFakeAssistantCnt' ,\n",
    "        'nFakeResistCnt' , \n",
    "        'nPriceUpCnt' , \n",
    "        'nPriceDownCnt' ,\n",
    "        'nTotalFakeCnt' ,\n",
    "        'nTotalFakeMinuteCnt' ,\n",
    "        'nUpCandleCnt' , \n",
    "        'nDownCandleCnt' ,\n",
    "        'nUpTailCnt' , \n",
    "        'nDownTailCnt' ,\n",
    "        'nShootingCnt' ,\n",
    "        'nCandleTwoOverRealCnt' ,\n",
    "        'nCandleTwoOverRealNoLeafCnt' , \n",
    "        'fSpeedCur' , \n",
    "        'fHogaSpeedCur' ,\n",
    "        'fTradeCur' , \n",
    "        'fPureTradeCur' , \n",
    "        'fPureBuyCur' , \n",
    "        'fHogaRatioCur' ,  \n",
    "        'fSharePerHoga' , \n",
    "        'fSharePerTrade' ,\n",
    "        'fHogaPerTrade' , \n",
    "        'fTradePerPure' , \n",
    "        'fMaDownFsVal' , \n",
    "        'fMa20mVal' , \n",
    "        'fMa1hVal' ,\n",
    "        'fMa2hVal' ,\n",
    "        'fMaxMaDownFsVal' ,\n",
    "        'fMaxMa20mVal' ,\n",
    "        'fMaxMa1hVal' ,\n",
    "        'fMaxMa2hVal' ,\n",
    "        'nMaxMaDownFsTime' ,\n",
    "        'nMaxMa20mTime' ,\n",
    "        'nMaxMa1hTime' ,\n",
    "        'nMaxMa2hTime' ,\n",
    "        'nDownCntMa20m' ,\n",
    "        'nDownCntMa1h' ,\n",
    "        'nDownCntMa2h' ,\n",
    "        'nUpCntMa20m' ,\n",
    "        'nUpCntMa1h' ,\n",
    "        'nUpCntMa2h' ,\n",
    "        'fMSlope' ,\n",
    "        'fISlope' ,\n",
    "        'fTSlope' ,\n",
    "        'fHSlope' ,\n",
    "        'fRSlope' ,\n",
    "        'fDSlope' ,\n",
    "        'fMAngle' ,\n",
    "        'fIAngle' ,\n",
    "        'fTAngle' ,\n",
    "        'fHAngle' ,\n",
    "        'fRAngle' ,\n",
    "        'fDAngle' ,\n",
    "        'nCrushCnt' ,\n",
    "        'nCrushUpCnt' ,\n",
    "        'nCrushDownCnt' ,\n",
    "        'nCrushSpecialDownCnt' \n",
    "]\n",
    "feature_size = len(feature_names_102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f47e039-04cf-4368-b596-9ed7f16284e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = br[\n",
    "   feature_names_102\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c58c12-1e03-4137-96f4-f02f56181113",
   "metadata": {},
   "source": [
    "# 스케일러 계산하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "059cc8a0-9177-42be-a15b-889698cd9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_s = None\n",
    "max_s = None\n",
    "mean_s = None\n",
    "std_s = None\n",
    "zero_s = None\n",
    "median_s = None\n",
    "iqr3_s = None\n",
    "iqr1_s = None\n",
    "\n",
    "MINMAX = 'MinMax'\n",
    "ROBUST = 'Robust'\n",
    "STANDARD = 'Standard'\n",
    "\n",
    "def setScaler(p_data):\n",
    "    np_data = p_data.to_numpy(dtype=np.float32)\n",
    "\n",
    "    row_num = np_data.shape[0]\n",
    "    col_num = np_data.shape[1]\n",
    "    \n",
    "    # global 사용\n",
    "    global min_s\n",
    "    global max_s\n",
    "    global mean_s\n",
    "    global std_s\n",
    "    global zero_s\n",
    "    global median_s\n",
    "    global iqr3_s\n",
    "    global iqr1_s\n",
    "    \n",
    "    # MinMaxScaler\n",
    "    min_s = np_data.min(axis=0)\n",
    "    max_s = np_data.max(axis=0)\n",
    "    \n",
    "    # StandardScaler\n",
    "    mean_s = np_data.mean(axis=0)\n",
    "    std_s = np_data.std(axis=0)\n",
    "    zero_s = np.zeros(col_num, dtype=np.float32)\n",
    "    \n",
    "    # RobustScaler\n",
    "    median_s = np.median(np_data, axis=0)\n",
    "    iqr3_s = np.quantile(np_data, q=0.75, axis=0)\n",
    "    iqr1_s = np.quantile(np_data, q=0.25, axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77653183-071c-4f31-8526-c0944a58af48",
   "metadata": {},
   "source": [
    "# 피처변수에 스케일링 적용 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8908757d-1014-48a1-a8d2-eea9ca094a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitMyScaler(p_data, scale_method='MinMax'):\n",
    "    np_data = p_data.to_numpy(dtype=np.float32)\n",
    "\n",
    "    row_num = np_data.shape[0]\n",
    "    col_num = np_data.shape[1]\n",
    "    \n",
    "    d0_s = None\n",
    "    d1_s = None\n",
    "    d2_s = None\n",
    "    \n",
    "    if scale_method == 'MinMax':\n",
    "        d0_s = min_s\n",
    "        d1_s = max_s\n",
    "        d2_s = min_s\n",
    "    elif scale_method == 'Standard':\n",
    "        d0_s = mean_s\n",
    "        d1_s = std_s\n",
    "        d2_s = zero_s\n",
    "    elif scale_method == 'Robust':\n",
    "        d0_s = median_s\n",
    "        d1_s = iqr3_s\n",
    "        d2_s = iqr1_s\n",
    "    else :\n",
    "        print('해당하는 스케일함수가 없습니다.')\n",
    "        return\n",
    "    \n",
    "    for i in range(col_num):\n",
    "        \n",
    "        d0 = d0_s[i]\n",
    "        d1 = d1_s[i]\n",
    "        d2 = d2_s[i]\n",
    "        \n",
    "        denom = d1 - d2\n",
    "        if denom == 0:\n",
    "            denom = 1\n",
    "                \n",
    "        for j in range(row_num):\n",
    "            np_data[j, i] = (np_data[j, i] - d0) / denom\n",
    "            \n",
    "            \n",
    "    return np_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42d3ee-3b12-4212-85c7-c8d028b31103",
   "metadata": {},
   "source": [
    "# 스케일 데이터 DB삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44f7588-0a25-40af-8488-d6e15f292e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteScaleData(table, feature_names, scale_method, model_name, pandas_data ):\n",
    "    try:\n",
    "        today = datetime.datetime.today()\n",
    "        scaleMethod = scale_method\n",
    "        sModel = model_name\n",
    "        \n",
    "        np_data = pandas_data.to_numpy(dtype=np.float32)\n",
    "        row_num = np_data.shape[0]\n",
    "        col_num = np_data.shape[1]\n",
    "        \n",
    "        d0_s = None\n",
    "        d1_s = None\n",
    "        d2_s = None\n",
    "    \n",
    "        if scale_method == 'MinMax':\n",
    "            d0_s = min_s\n",
    "            d1_s = max_s\n",
    "            d2_s = min_s\n",
    "        elif scale_method == 'Standard':\n",
    "            d0_s = mean_s\n",
    "            d1_s = std_s\n",
    "            d2_s = zero_s\n",
    "        elif scale_method == 'Robust':\n",
    "            d0_s = median_s\n",
    "            d1_s = iqr3_s\n",
    "            d2_s = iqr1_s\n",
    "        else :\n",
    "            print('해당하는 스케일함수가 없습니다.')\n",
    "            return\n",
    "        \n",
    "        \n",
    "        for idx, col in enumerate(feature_names):\n",
    "            sVar = col\n",
    "            \n",
    "            d0 = d0_s[idx]\n",
    "            d1 = d1_s[idx]\n",
    "            d2 = d2_s[idx]\n",
    "            \n",
    "            denom = d1 - d2\n",
    "            if denom == 0:\n",
    "                d1 = 1\n",
    "                d2 = 0 \n",
    "            \n",
    "            query = db.insert(table).values( {'dTime': today, 'sScaleMethod':scaleMethod, 'sVariableName':sVar, \n",
    "                            'sModelName':sModel, 'fD0':d0, 'fD1':d1, 'fD2':d2, 'nSeq':idx})\n",
    "            result_proxy = conn.execute(query)\n",
    "            result_proxy.close()\n",
    "        print('put scale to ', sModel, ' ends')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af349e37-d829-443f-af14-577e07d36383",
   "metadata": {},
   "source": [
    "# 스케일 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62c6356-3d8f-48cb-8b7c-1dbb477a71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_method = ROBUST\n",
    "\n",
    "# 테스트 상 스케일 방법 중 Normalizer는 좋지 않다.\n",
    "setScaler(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd8136-853b-412f-a890-1c6ba39d8d7c",
   "metadata": {},
   "source": [
    "# 모델명 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22f194f-4ae6-4bfb-a465-26e421203481",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = './h5/'  \n",
    "checkpoint_path = './checkpoint/'\n",
    "onnx_path = './onnx/'\n",
    "tmp_model_path = './model_tmp/'\n",
    "\n",
    "h5 = '.h5'\n",
    "onnx = '.onnx'\n",
    "\n",
    "model_name = 'fMax30_50_drop'\n",
    "\n",
    "call_back_acc_max_filename = model_name + '_' + scale_method + '_ac_max' \n",
    "call_back_loss_min_filename = model_name + '_' + scale_method + '_ls_min'\n",
    "call_back_last_filename = model_name + '_' + scale_method + '_last'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c091d1-ade7-42fc-82db-88ff403fa138",
   "metadata": {},
   "source": [
    "# 스케일링 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239ef22f-bf89-42c3-8db0-3f432d2e6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-0.6805556   0.00704231 -0.21659644 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.8472222   1.3594652  -0.67948395 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.8333333   1.3624549  -0.67948395 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.5555556   1.0131629  -0.75302684 ...  2.          1.\n",
      "   0.        ]\n",
      " [ 0.5694444   1.0131629  -0.75302684 ...  2.          1.\n",
      "   0.        ]\n",
      " [ 0.5972222   1.0131629  -0.75302684 ...  2.          1.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = fitMyScaler(X, scale_method)\n",
    "\n",
    "print(type(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941c787-d3b0-4ea6-840f-fa88b0e7019c",
   "metadata": {},
   "source": [
    "# 타겟변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb68695-532f-44eb-8d3f-873845f84229",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_condition = (br['fMaxPowerAfterBuyWhile30'] >= 0.05)\n",
    "br.loc[y_condition , 'target'] = 1\n",
    "br.loc[~y_condition, 'target'] = 0\n",
    "y = br['target']\n",
    "\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119f085-84a3-4e90-9cc4-2a9964de168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "br['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000502c-5725-4cb7-9af1-d241e0c03ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = int(1 / (random.random() + 0.00000001) * 100)\n",
    "random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8622a8-7607-4704-8c1c-f74239c759ac",
   "metadata": {},
   "source": [
    "# 데이터 스플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8010c47-713d-47e8-a665-9bc814c1c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98022fe4-374b-472c-b543-c1064dc11c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train : ', X_train.shape)\n",
    "print('y_train : ', y_train.shape)\n",
    "print('X_train : ', X_valid.shape)\n",
    "print('y_train : ', y_valid.shape)\n",
    "print('X_test  : ', X_test.shape)\n",
    "print('y_test  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbe567-cf95-4ee3-9978-57ac87f12f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputDim = feature_size\n",
    "nOutputDim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb6e99-8ba3-41e1-9807-94000ae90855",
   "metadata": {},
   "source": [
    "# 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975db5e-dd74-4150-96bc-d89a60ce0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(nInputDim), name='input')\n",
    "x = Dense(512, activation='relu')(main_input)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "main_output = Dense(nOutputDim, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0aa448-d364-450b-b063-2ee99a989e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=main_input, outputs=main_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6a0b1-6232-469a-af25-810166efd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc015a-9419-49fa-bea5-25fefb89d62d",
   "metadata": {},
   "source": [
    "# 에포크와 배치사이즈 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6eafa-663d-43a6-bdc2-28b117a67056",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee175ffb-02c0-4815-86b8-d39166123c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ac2db-5cab-4a5c-9a63-e0d5e67eef6c",
   "metadata": {},
   "source": [
    "# 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a435d82-783b-426d-aa3e-6482027b8fbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validation data 있다면\n",
    "call_back_acc_max_filename_h5 = call_back_acc_max_filename + h5\n",
    "filename_acc = checkpoint_path + call_back_acc_max_filename_h5\n",
    "checkpoint_acc = ModelCheckpoint(filename_acc,\n",
    "                            monitor='val_accuracy',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "\n",
    "call_back_loss_min_filename_h5 = call_back_loss_min_filename + h5\n",
    "filename_loss = checkpoint_path + call_back_loss_min_filename_h5\n",
    "checkpoint_loss = ModelCheckpoint(filename_loss,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n",
    "\n",
    "call_back_last_filename_h5 = call_back_last_filename + h5\n",
    "filename_last = checkpoint_path + call_back_last_filename_h5\n",
    "checkpoint_last = ModelCheckpoint(filename_last,\n",
    "                            verbose=1,\n",
    "                            save_freq = 'epoch'\n",
    "                            )\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "      validation_data=(X_valid, y_valid),\n",
    "      epochs=EPOCH, \n",
    "      batch_size=BATCH_SIZE, \n",
    "      callbacks=[checkpoint_acc, checkpoint_loss, checkpoint_last] # checkpoint 콜백\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383d1fc-b4e9-4635-bc66-010bcf95b789",
   "metadata": {},
   "source": [
    "# 모델 임시평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c91f770e-c62b-4e7a-a0be-f6b70f621b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-03990686ab1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('accuracy : ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6726e-720b-4401-bfbd-0e8c61d46145",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2ee67-1520-450a-aea0-fb011875e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "ac = 0\n",
    "fl = 0\n",
    "d_ac = 0\n",
    "d_fl = 0\n",
    "\n",
    "suc_crit = 0.8\n",
    "fl_crit = 0.5\n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if(y_test[i] == 1.0):\n",
    "        one += 1\n",
    "    elif(y_test[i] == 0.0):\n",
    "        zero += 1\n",
    "        \n",
    "    if y_pred[i] > suc_crit:\n",
    "        if(y_test[i] == 1.0):\n",
    "            ac += 1\n",
    "        else:\n",
    "            fl += 1\n",
    "            \n",
    "    if y_pred[i] < fl_crit:\n",
    "        if(y_test[i] == 0.0):\n",
    "            d_ac += 1\n",
    "        else:\n",
    "            d_fl += 1\n",
    "    \n",
    "print('총량 : ', one+zero)\n",
    "print('0 : ', zero, ', 비율 : ', (zero / (1 if one+zero == 0 else one+zero)) * 100, '(%)')\n",
    "print('1 : ', one, ', 비율 : ', (one / (1 if one+zero == 0 else one+zero)) * 100, '(%)', end='\\n\\n')\n",
    "\n",
    "print('============ predict 0 =============')\n",
    "print('총 횟수 : ', d_ac+ d_fl, ',  타겟기준 : ', fl_crit)\n",
    "print('실제 0 : ', d_ac)\n",
    "print('실제 1 : ', d_fl)\n",
    "print('정답비율 : ', (d_ac / (1 if d_ac+d_fl == 0 else d_ac+d_fl)) * 100, '(%)', end='\\n\\n')\n",
    "    \n",
    "print('============ predict 1 =============')\n",
    "print('총 횟수 : ', ac+ fl, ', 타겟기준 : ', suc_crit)\n",
    "print('실제 1 : ', ac)\n",
    "print('실제 0 : ', fl)\n",
    "print('정답비율 : ', (ac / (1 if ac+fl == 0 else ac+fl)) * 100, '(%)', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d2e89-3a3f-47cc-b359-cb5f1541e442",
   "metadata": {},
   "source": [
    "# 모델 적용 (자동)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1018ef0d-c74d-49a2-ae99-c6aad87e79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./model_tmp/assets\n",
      "put scale to  fMax30_50_drop_Robust_last.onnx  ends\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./model_tmp/assets\n",
      "put scale to  fMax30_50_drop_Robust_ac_max.onnx  ends\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./model_tmp/assets\n",
      "put scale to  fMax30_50_drop_Robust_ls_min.onnx  ends\n"
     ]
    }
   ],
   "source": [
    "# 세 모델 다 저장하려고 한다면\n",
    "li_filename = [call_back_last_filename, call_back_acc_max_filename, call_back_loss_min_filename]\n",
    "\n",
    "for fn in li_filename:\n",
    "    load_selection_name = fn\n",
    "    # h5 to pb\n",
    "    model_convert = tf.keras.models.load_model(checkpoint_path + load_selection_name + h5, compile=False)\n",
    "    model_convert.save(h5_path + load_selection_name + h5)\n",
    "    model_convert.save(tmp_model_path, save_format=\"tf\")\n",
    "\n",
    "    # pb to onnx \n",
    "    os.system('python -m tf2onnx.convert --saved-model ' +  tmp_model_path + ' --output ' + onnx_path + load_selection_name + onnx + ' --opset 13')\n",
    "\n",
    "    metadata = db.MetaData()\n",
    "    table = db.Table('scaleDatasDict', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "    WriteScaleData(table=table, feature_names=feature_names_102, scale_method=scale_method,\n",
    "     model_name=load_selection_name + onnx, pandas_data=br[feature_names_102])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a515ea-6913-4a29-bd2f-39726f6d3ea0",
   "metadata": {},
   "source": [
    "# 모델 적용 (수동)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8e0ba-df9a-4762-a60b-ade92bd7fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST = 0\n",
    "ACC = 1\n",
    "LOSS = 2\n",
    "\n",
    "n_put = LAST\n",
    "load_selection_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b5f79-3279-4a5c-84b3-0c0d09986a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_put == LAST :\n",
    "    load_selection_name = call_back_last_filename\n",
    "elif n_put == ACC:\n",
    "    load_selection_name = call_back_acc_max_filename\n",
    "elif n_put == LOSS:\n",
    "    load_selection_name = call_back_loss_min_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024b605-5044-4e79-a9eb-9ebf5157f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # h5 to pb\n",
    "# model_convert = tf.keras.models.load_model(checkpoint_path + load_selection_name + h5, compile=False)\n",
    "# model_convert.save(h5_path + load_selection_name + h5)\n",
    "# model_convert.save(tmp_model_path, save_format=\"tf\")\n",
    "\n",
    "# # pb to onnx \n",
    "# os.system('python -m tf2onnx.convert --saved-model ' +  tmp_model_path + ' --output ' + onnx_path + load_selection_name + onnx + ' --opset 13')\n",
    "\n",
    "# metadata = db.MetaData()\n",
    "# table = db.Table('scaleDatasDict', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# WriteScaleData(table=table, feature_names=feature_names_102, scale_method=scale_method,\n",
    "#  model_name=load_selection_name + onnx, pandas_data=br[feature_names_102])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3299149-dc84-49d9-b964-efb2ed6a5894",
   "metadata": {},
   "source": [
    "# 수동 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f5a73-439d-4e84-830a-52ee43499b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트?? 단순히 테스트하는 곳임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f43b57-0735-4212-b743-133f585d357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = br2[\n",
    "   feature_names_102\n",
    "]\n",
    "\n",
    "y2= br2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33e6a5-f805-4975-b9f1-53c1393a91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_method2 = ROBUST\n",
    "X2 = fitMyScaler(X2, scale_method2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46e815-9ac4-48eb-b7b0-101ad48a4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X2 \n",
    "y_test = y2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e508f624-d745-4a0c-b019-8c758f0cc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_h5_path = './h5/'\n",
    "t_model_name = ['fProfit_10_Robust_100_c', 'fProfit_10_Robust_c','fProfit_10_Droupout2','fProfit_10_Robust_c_reuse', 'checkpoint-standard-400-100-loss-min']\n",
    "t_save_model_name = [name + '.h5' for  name in t_model_name]\n",
    "\n",
    "models = []\n",
    "for i in t_save_model_name:\n",
    "    model_tmp = tf.keras.models.load_model(t_h5_path + i, compile=False)\n",
    "    models.append( model_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa251a32-886f-449a-b8fb-bc974d0e03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 8ms/step\n",
      "138/138 [==============================] - 1s 8ms/step\n",
      "138/138 [==============================] - 1s 8ms/step\n",
      "138/138 [==============================] - 1s 7ms/step\n",
      "138/138 [==============================] - 3s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = models[0].predict(X_test)\n",
    "y_pred2 = models[1].predict(X_test)\n",
    "y_pred3 = models[2].predict(X_test)\n",
    "y_pred4 = models[3].predict(X_test)\n",
    "y_pred5 = models[4].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cea185c-7622-4d21-9d88-5c5f77943c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총량 :  4392\n",
      "0 :  3893 , 비율 :  88.63843351548269 (%)\n",
      "1 :  499 , 비율 :  11.361566484517304 (%)\n",
      "\n",
      "============ predict 0 =============\n",
      "총 횟수 :  2468 ,  타겟기준 :  0.5\n",
      "실제 0 :  2139\n",
      "실제 1 :  329\n",
      "정답비율 :  86.66936790923825 (%)\n",
      "\n",
      "============ predict 1 =============\n",
      "총 횟수 :  545 , 타겟기준 :  0.7\n",
      "실제 1 :  35\n",
      "실제 0 :  510\n",
      "정답비율 :  6.422018348623854 (%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "ac = 0\n",
    "fl = 0\n",
    "d_ac = 0\n",
    "d_fl = 0\n",
    "\n",
    "suc_crit = 0.7\n",
    "fl_crit = 0.5\n",
    "\n",
    "len_y = y_test.shape[0]\n",
    "y_pred = [y_pred1, y_pred2, y_pred3, y_pred4, y_pred5]\n",
    "\n",
    "suc_ratio = 0.6\n",
    "suc_line = int(len(y_pred) * suc_ratio)\n",
    "\n",
    "fail_ratio = 1.0\n",
    "fail_line = int(len(y_pred) * fail_ratio)\n",
    "\n",
    "for i in range(len_y):\n",
    "    if(y_test[i] == 1.0):\n",
    "        one += 1\n",
    "    elif(y_test[i] == 0.0):\n",
    "        zero += 1\n",
    "        \n",
    "    # PREDICT 0\n",
    "    pass_0 = False\n",
    "    pass_0_check = 0 \n",
    "    for pred in y_pred:\n",
    "        if pred[i][0] < fl_crit :\n",
    "            pass_0_check += 1\n",
    "            \n",
    "    if pass_0_check >= fail_line:\n",
    "        pass_0 = True\n",
    "            \n",
    "    if pass_0: \n",
    "        if(y_test[i] == 0.0):\n",
    "            d_ac += 1\n",
    "        else:\n",
    "            d_fl += 1\n",
    "    \n",
    "    # PREDICT 1\n",
    "    pass_1 = False\n",
    "    pass_1_check = 0 \n",
    "    for pred in y_pred:\n",
    "        if pred[i][0] > suc_crit :\n",
    "            pass_1_check += 1\n",
    "            \n",
    "    if pass_1_check >= suc_line:\n",
    "        pass_1 = True\n",
    "            \n",
    "    if pass_1: \n",
    "        if(y_test[i] == 1.0):\n",
    "            ac += 1\n",
    "        else:\n",
    "            fl += 1\n",
    "\n",
    "   \n",
    "    \n",
    "print('총량 : ', one+zero)\n",
    "print('0 : ', zero, ', 비율 : ', (zero / (1 if one+zero == 0 else one+zero)) * 100, '(%)')\n",
    "print('1 : ', one, ', 비율 : ', (one / (1 if one+zero == 0 else one+zero)) * 100, '(%)', end='\\n\\n')\n",
    "\n",
    "print('============ predict 0 =============')\n",
    "print('총 횟수 : ', d_ac+ d_fl, ',  타겟기준 : ', fl_crit)\n",
    "print('실제 0 : ', d_ac)\n",
    "print('실제 1 : ', d_fl)\n",
    "print('정답비율 : ', (d_ac / (1 if d_ac+d_fl == 0 else d_ac+d_fl)) * 100, '(%)', end='\\n\\n')\n",
    "    \n",
    "print('============ predict 1 =============')\n",
    "print('총 횟수 : ', ac+ fl, ', 타겟기준 : ', suc_crit)\n",
    "print('실제 1 : ', ac)\n",
    "print('실제 0 : ', fl)\n",
    "print('정답비율 : ', (ac / (1 if ac+fl == 0 else ac+fl)) * 100, '(%)', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59d9c8-ec96-417b-a1f9-00f687ce96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0\n",
    "]\n",
    "p = pd.DataFrame(li).T\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f484c-637b-495e-843b-20493c35b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = fitMyScaler(p, ROBUST)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffb44e-232c-4c10-89f8-552c63211f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf2ea0-0c42-417c-858a-6fa50c841961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
