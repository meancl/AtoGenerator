{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6e663b-eb93-4ebb-9fbb-4c3eba485bdc",
   "metadata": {},
   "source": [
    "# 데이터 획득 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b990c0fc-a349-4d91-a368-f5d2724d69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc24889c-cf5c-4f89-b1f7-407161d64f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql://sbe03253:jin94099@database-2.clmg3ftdxi2a.ap-northeast-2.rds.amazonaws.com/MJTradierDB')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8801b92f-451c-4356-8ace-75599e939d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = pd.read_sql_table('buyReports', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6608fa50-6218-4185-ae8c-f388886a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "get_filter = ( br['isAllBuyed'] == 1) & ( br['isAllSelled'] == 1) & (br['nBuyVolume'] > 0)\n",
    "# get_filter = get_filter & (br['dTradeTime'] >= datetime.datetime(2023, 2, 1))\n",
    "br = br[get_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e94819-45cb-4aa1-839f-5b7efa098597",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_102 =  [   \n",
    "        'nBuyStrategyIdx',\n",
    "        'nRqTime' , \n",
    "        'fStartGap' ,\n",
    "        'fPowerWithOutGap' , \n",
    "        'fPower' , \n",
    "        'fPlusCnt07' , \n",
    "        'fMinusCnt07' , \n",
    "        'fPlusCnt09' , \n",
    "        'fMinusCnt09' ,\n",
    "        'fPowerJar' , \n",
    "        'fOnlyDownPowerJar' , \n",
    "        'fOnlyUpPowerJar' , \n",
    "        'nTradeCnt' , \n",
    "        'nChegyulCnt' , \n",
    "        'nHogaCnt' , \n",
    "        'nNoMoveCnt' , \n",
    "        'nFewSpeedCnt' ,\n",
    "        'nMissCnt' , \n",
    "        'lTotalTradeVolume' , \n",
    "        'lTotalBuyVolume' , \n",
    "        'lTotalSellVolume' ,\n",
    "        'nAccumUpDownCount' ,\n",
    "        'fAccumUpPower' , \n",
    "        'fAccumDownPower' ,\n",
    "        'lTotalTradePrice' , \n",
    "        'lTotalBuyPrice' , \n",
    "        'lTotalSellPrice' , \n",
    "        'lMarketCap' , \n",
    "        'nAccumCountRanking' , \n",
    "        'nMarketCapRanking' , \n",
    "        'nPowerRanking' , \n",
    "        'nTotalBuyPriceRanking' , \n",
    "        'nTotalBuyVolumeRanking' ,\n",
    "        'nTotalTradePriceRanking' ,\n",
    "        'nTotalTradeVolumeRanking' ,\n",
    "        'nTotalRank' , \n",
    "        'nMinuteTotalRank' , \n",
    "        'nMinuteTradePriceRanking' ,\n",
    "        'nMinuteTradeVolumeRanking' , \n",
    "        'nMinuteBuyPriceRanking' , \n",
    "        'nMinuteBuyVolumeRanking' ,\n",
    "        'nMinutePowerRanking' , \n",
    "        'nMinuteCountRanking' ,\n",
    "        'nMinuteUpDownRanking' ,\n",
    "        'nFakeBuyCnt' , \n",
    "        'nFakeAssistantCnt' ,\n",
    "        'nFakeResistCnt' , \n",
    "        'nPriceUpCnt' , \n",
    "        'nPriceDownCnt' ,\n",
    "        'nTotalFakeCnt' ,\n",
    "        'nTotalFakeMinuteCnt' ,\n",
    "        'nUpCandleCnt' , \n",
    "        'nDownCandleCnt' ,\n",
    "        'nUpTailCnt' , \n",
    "        'nDownTailCnt' ,\n",
    "        'nShootingCnt' ,\n",
    "        'nCandleTwoOverRealCnt' ,\n",
    "        'nCandleTwoOverRealNoLeafCnt' , \n",
    "        'fSpeedCur' , \n",
    "        'fHogaSpeedCur' ,\n",
    "        'fTradeCur' , \n",
    "        'fPureTradeCur' , \n",
    "        'fPureBuyCur' , \n",
    "        'fHogaRatioCur' ,  \n",
    "        'fSharePerHoga' , \n",
    "        'fSharePerTrade' ,\n",
    "        'fHogaPerTrade' , \n",
    "        'fTradePerPure' , \n",
    "        'fMaDownFsVal' , \n",
    "        'fMa20mVal' , \n",
    "        'fMa1hVal' ,\n",
    "        'fMa2hVal' ,\n",
    "        'fMaxMaDownFsVal' ,\n",
    "        'fMaxMa20mVal' ,\n",
    "        'fMaxMa1hVal' ,\n",
    "        'fMaxMa2hVal' ,\n",
    "        'nMaxMaDownFsTime' ,\n",
    "        'nMaxMa20mTime' ,\n",
    "        'nMaxMa1hTime' ,\n",
    "        'nMaxMa2hTime' ,\n",
    "        'nDownCntMa20m' ,\n",
    "        'nDownCntMa1h' ,\n",
    "        'nDownCntMa2h' ,\n",
    "        'nUpCntMa20m' ,\n",
    "        'nUpCntMa1h' ,\n",
    "        'nUpCntMa2h' ,\n",
    "        'fMSlope' ,\n",
    "        'fISlope' ,\n",
    "        'fTSlope' ,\n",
    "        'fHSlope' ,\n",
    "        'fRSlope' ,\n",
    "        'fDSlope' ,\n",
    "        'fMAngle' ,\n",
    "        'fIAngle' ,\n",
    "        'fTAngle' ,\n",
    "        'fHAngle' ,\n",
    "        'fRAngle' ,\n",
    "        'fDAngle' ,\n",
    "        'nCrushCnt' ,\n",
    "        'nCrushUpCnt' ,\n",
    "        'nCrushDownCnt' ,\n",
    "        'nCrushSpecialDownCnt' \n",
    "]\n",
    "feature_size = len(feature_names_102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f47e039-04cf-4368-b596-9ed7f16284e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float32범위보다 높은 double값이 있어 inf로 계산됨 \n",
    "# 오류발생 가능성이 있어 값의 상한선을 둠\n",
    "BILLION = 1000000000\n",
    "br.loc[ br['fSharePerHoga'] > BILLION, 'fSharePerHoga'] = BILLION \n",
    "br.loc[ br['fHogaPerTrade'] > BILLION, 'fHogaPerTrade'] = BILLION\n",
    "br.loc[ br['fSharePerTrade'] > BILLION, 'fSharePerTrade'] = BILLION\n",
    "br.loc[ br['fTradePerPure'] > BILLION, 'fTradePerPure'] = BILLION\n",
    "\n",
    "\n",
    "X = br[\n",
    "   feature_names_102\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059cc8a0-9177-42be-a15b-889698cd9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_s = None\n",
    "max_s = None\n",
    "mean_s = None\n",
    "std_s = None\n",
    "zero_s = None\n",
    "median_s = None\n",
    "iqr3_s = None\n",
    "iqr1_s = None\n",
    "\n",
    "MINMAX = 'MinMax'\n",
    "ROBUST = 'Robust'\n",
    "STANDARD = 'Standard'\n",
    "\n",
    "def setScaler(p_data):\n",
    "    np_data = p_data.to_numpy(dtype=np.float32)\n",
    "\n",
    "    row_num = np_data.shape[0]\n",
    "    col_num = np_data.shape[1]\n",
    "    \n",
    "    # global 사용\n",
    "    global min_s\n",
    "    global max_s\n",
    "    global mean_s\n",
    "    global std_s\n",
    "    global zero_s\n",
    "    global median_s\n",
    "    global iqr3_s\n",
    "    global iqr1_s\n",
    "    \n",
    "    # MinMaxScaler\n",
    "    min_s = np_data.min(axis=0)\n",
    "    max_s = np_data.max(axis=0)\n",
    "    \n",
    "    # StandardScaler\n",
    "    mean_s = np_data.mean(axis=0)\n",
    "    std_s = np_data.std(axis=0)\n",
    "    zero_s = np.zeros(col_num, dtype=np.float32)\n",
    "    \n",
    "    # RobustScaler\n",
    "    median_s = np.median(np_data, axis=0)\n",
    "    iqr3_s = np.quantile(np_data, q=0.75, axis=0)\n",
    "    iqr1_s = np.quantile(np_data, q=0.25, axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8908757d-1014-48a1-a8d2-eea9ca094a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitMyScaler(p_data, scale_method='MinMax'):\n",
    "    np_data = p_data.to_numpy(dtype=np.float32)\n",
    "\n",
    "    row_num = np_data.shape[0]\n",
    "    col_num = np_data.shape[1]\n",
    "    \n",
    "    d0_s = None\n",
    "    d1_s = None\n",
    "    d2_s = None\n",
    "    \n",
    "    if scale_method == 'MinMax':\n",
    "        d0_s = min_s\n",
    "        d1_s = max_s\n",
    "        d2_s = min_s\n",
    "    elif scale_method == 'Standard':\n",
    "        d0_s = mean_s\n",
    "        d1_s = std_s\n",
    "        d2_s = zero_s\n",
    "    elif scale_method == 'Robust':\n",
    "        d0_s = median_s\n",
    "        d1_s = iqr3_s\n",
    "        d2_s = iqr1_s\n",
    "    else :\n",
    "        print('해당하는 스케일함수가 없습니다.')\n",
    "        return\n",
    "    \n",
    "    for i in range(col_num):\n",
    "        \n",
    "        d0 = d0_s[i]\n",
    "        d1 = d1_s[i]\n",
    "        d2 = d2_s[i]\n",
    "        \n",
    "        denom = d1 - d2\n",
    "        if denom == 0:\n",
    "            denom = 1\n",
    "                \n",
    "        for j in range(row_num):\n",
    "            np_data[j, i] = (np_data[j, i] - d0) / denom\n",
    "            \n",
    "            \n",
    "    return np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44f7588-0a25-40af-8488-d6e15f292e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteScaleData(table, feature_names, scale_method, model_name, pandas_data ):\n",
    "    try:\n",
    "        today = datetime.datetime.today()\n",
    "        scaleMethod = scale_method\n",
    "        sModel = model_name\n",
    "        \n",
    "        np_data = pandas_data.to_numpy(dtype=np.float32)\n",
    "        row_num = np_data.shape[0]\n",
    "        col_num = np_data.shape[1]\n",
    "        \n",
    "        d0_s = None\n",
    "        d1_s = None\n",
    "        d2_s = None\n",
    "    \n",
    "        if scale_method == 'MinMax':\n",
    "            d0_s = min_s\n",
    "            d1_s = max_s\n",
    "            d2_s = min_s\n",
    "        elif scale_method == 'Standard':\n",
    "            d0_s = mean_s\n",
    "            d1_s = std_s\n",
    "            d2_s = zero_s\n",
    "        elif scale_method == 'Robust':\n",
    "            d0_s = median_s\n",
    "            d1_s = iqr3_s\n",
    "            d2_s = iqr1_s\n",
    "        else :\n",
    "            print('해당하는 스케일함수가 없습니다.')\n",
    "            return\n",
    "        \n",
    "        \n",
    "        for idx, col in enumerate(feature_names):\n",
    "            sVar = col\n",
    "            \n",
    "            d0 = d0_s[idx]\n",
    "            d1 = d1_s[idx]\n",
    "            d2 = d2_s[idx]\n",
    "            \n",
    "            denom = d1 - d2\n",
    "            if denom == 0:\n",
    "                d1 = 1\n",
    "                d2 = 0 \n",
    "            \n",
    "            query = db.insert(table).values( {'dTime': today, 'sScaleMethod':scaleMethod, 'sVariableName':sVar, \n",
    "                            'sModelName':sModel, 'fD0':d0, 'fD1':d1, 'fD2':d2, 'nSeq':idx})\n",
    "            result_proxy = conn.execute(query)\n",
    "            result_proxy.close()\n",
    "        print('put scale to ', sModel, ' ends')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62c6356-3d8f-48cb-8b7c-1dbb477a71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 상 스케일 방법 중 Normalizer는 좋지 않다.\n",
    "setScaler(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239ef22f-bf89-42c3-8db0-3f432d2e6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-0.6805556   0.00704231 -0.21659644 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.8472222   1.3594652  -0.67948395 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.8333333   1.3624549  -0.67948395 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.5555556   1.0131629  -0.75302684 ...  2.          1.\n",
      "   0.        ]\n",
      " [ 0.5694444   1.0131629  -0.75302684 ...  2.          1.\n",
      "   0.        ]\n",
      " [ 0.5972222   1.0131629  -0.75302684 ...  2.          1.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "scale_method = ROBUST\n",
    "X = fitMyScaler(X, scale_method)\n",
    "\n",
    "print(type(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bb68695-532f-44eb-8d3f-873845f84229",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = 0.01\n",
    "target_col_name = 'fProfit'\n",
    "y_condition = (br[target_col_name] >= crit)\n",
    "br.loc[y_condition , 'target'] = 1\n",
    "br.loc[~y_condition, 'target'] = 0\n",
    "y = br['target']\n",
    "\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5119f085-84a3-4e90-9cc4-2a9964de168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6000502c-5725-4cb7-9af1-d241e0c03ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = int(1 / (random.random() + 0.00000001) * 100)\n",
    "random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8010c47-713d-47e8-a665-9bc814c1c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98022fe4-374b-472c-b543-c1064dc11c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (41853, 102)\n",
      "y_train :  (41853,)\n",
      "X_train :  (13951, 102)\n",
      "y_train :  (13951,)\n",
      "X_test  :  (13952, 102)\n",
      "y_test  :  (13952,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train : ', X_train.shape)\n",
    "print('y_train : ', y_train.shape)\n",
    "print('X_train : ', X_valid.shape)\n",
    "print('y_train : ', y_valid.shape)\n",
    "print('X_test  : ', X_test.shape)\n",
    "print('y_test  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34dbe567-cf95-4ee3-9978-57ac87f12f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputDim = feature_size\n",
    "nOutputDim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f22f194f-4ae6-4bfb-a465-26e421203481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_path = './h5/'  \n",
    "checkpoint_path = './checkpoint/'\n",
    "onnx_path = './onnx/'\n",
    "tmp_model_path = './model_tmp/'\n",
    "\n",
    "h5 = '.h5'\n",
    "onnx = '.onnx'\n",
    "\n",
    "model_name = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f975db5e-dd74-4150-96bc-d89a60ce0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(nInputDim), name='input')\n",
    "x = Dense(128, activation='relu')(main_input)\n",
    "# x = Dropout(.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "main_output = Dense(nOutputDim, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de0aa448-d364-450b-b063-2ee99a989e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=main_input, outputs=main_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ee6a0b1-6232-469a-af25-810166efd54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 102)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               13184     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 473,729\n",
      "Trainable params: 473,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f6eafa-663d-43a6-bdc2-28b117a67056",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee175ffb-02c0-4815-86b8-d39166123c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a435d82-783b-426d-aa3e-6482027b8fbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "650/654 [============================>.] - ETA: 0s - loss: 721.5334 - accuracy: 0.7731\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78116, saving model to ./checkpoint\\Test_Robust_ac_max.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 10.10470, saving model to ./checkpoint\\Test_Robust_ls_min.h5\n",
      "\n",
      "Epoch 1: saving model to ./checkpoint\\Test_Robust_last.h5\n",
      "654/654 [==============================] - 8s 10ms/step - loss: 717.1751 - accuracy: 0.7731 - val_loss: 10.1047 - val_accuracy: 0.7812\n",
      "Epoch 2/3\n",
      "654/654 [==============================] - ETA: 0s - loss: 5.8415 - accuracy: 0.7759\n",
      "Epoch 2: val_accuracy did not improve from 0.78116\n",
      "\n",
      "Epoch 2: val_loss improved from 10.10470 to 0.54801, saving model to ./checkpoint\\Test_Robust_ls_min.h5\n",
      "\n",
      "Epoch 2: saving model to ./checkpoint\\Test_Robust_last.h5\n",
      "654/654 [==============================] - 6s 9ms/step - loss: 5.8415 - accuracy: 0.7759 - val_loss: 0.5480 - val_accuracy: 0.7812\n",
      "Epoch 3/3\n",
      "651/654 [============================>.] - ETA: 0s - loss: 0.5924 - accuracy: 0.7764\n",
      "Epoch 3: val_accuracy did not improve from 0.78116\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.54801\n",
      "\n",
      "Epoch 3: saving model to ./checkpoint\\Test_Robust_last.h5\n",
      "654/654 [==============================] - 6s 10ms/step - loss: 0.5923 - accuracy: 0.7763 - val_loss: 0.5713 - val_accuracy: 0.7777\n"
     ]
    }
   ],
   "source": [
    "# validation data 있다면\n",
    "\n",
    "call_back_acc_max_filename = model_name + '_' + scale_method + '_ac_max' \n",
    "call_back_acc_max_filename_h5 = call_back_acc_max_filename + h5\n",
    "filename_acc = checkpoint_path + call_back_acc_max_filename_h5\n",
    "checkpoint_acc = ModelCheckpoint(filename_acc,\n",
    "                            monitor='val_accuracy',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "\n",
    "call_back_loss_min_filename = model_name + '_' + scale_method + '_ls_min'\n",
    "call_back_loss_min_filename_h5 = call_back_loss_min_filename + h5\n",
    "filename_loss = checkpoint_path + call_back_loss_min_filename_h5\n",
    "checkpoint_loss = ModelCheckpoint(filename_loss,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n",
    "\n",
    "call_back_last_filename = model_name + '_' + scale_method + '_last'\n",
    "call_back_last_filename_h5 = call_back_last_filename + h5\n",
    "filename_last = checkpoint_path + call_back_last_filename_h5\n",
    "checkpoint_last = ModelCheckpoint(filename_last,\n",
    "                            verbose=1,\n",
    "                            save_freq = 'epoch'\n",
    "                            )\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "      validation_data=(X_valid, y_valid),\n",
    "      epochs=EPOCH, \n",
    "      batch_size=BATCH_SIZE, \n",
    "      callbacks=[checkpoint_acc, checkpoint_loss, checkpoint_last] # checkpoint 콜백\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c91f770e-c62b-4e7a-a0be-f6b70f621b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/436 [==============================] - 2s 4ms/step - loss: 0.5505 - accuracy: 0.7721\n",
      "accuracy :  77.21473574638367\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('accuracy : ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fe6726e-720b-4401-bfbd-0e8c61d46145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/436 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89f2ee67-1520-450a-aea0-fb011875e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기준명 :  fProfit , 기준값 :  0.01\n",
      "총량 :  13952\n",
      "0 :  10803 , 비율 :  77.42975917431193 (%)\n",
      "1 :  3149 , 비율 :  22.570240825688074 (%)\n",
      "\n",
      "============ predict 0 =============\n",
      "총 횟수 :  13908 ,  타겟기준 :  0.5\n",
      "실제 0 :  10766\n",
      "실제 1 :  3142\n",
      "정답비율 :  77.4086856485476 (%)\n",
      "\n",
      "============ predict 1 =============\n",
      "총 횟수 :  27 , 타겟기준 :  0.8\n",
      "실제 1 :  6\n",
      "실제 0 :  21\n",
      "정답비율 :  22.22222222222222 (%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "ac = 0\n",
    "fl = 0\n",
    "d_ac = 0\n",
    "d_fl = 0\n",
    "\n",
    "suc_crit = 0.8\n",
    "fl_crit = 0.5\n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if(y_test[i] == 1.0):\n",
    "        one += 1\n",
    "    elif(y_test[i] == 0.0):\n",
    "        zero += 1\n",
    "        \n",
    "    if y_pred[i] > suc_crit:\n",
    "        if(y_test[i] == 1.0):\n",
    "            ac += 1\n",
    "        else:\n",
    "            fl += 1\n",
    "            \n",
    "    if y_pred[i] < fl_crit:\n",
    "        if(y_test[i] == 0.0):\n",
    "            d_ac += 1\n",
    "        else:\n",
    "            d_fl += 1\n",
    "    \n",
    "print('기준명 : ', target_col_name, ', 기준값 : ', crit)\n",
    "print('총량 : ', one+zero)\n",
    "print('0 : ', zero, ', 비율 : ', (zero / (1 if one+zero == 0 else one+zero)) * 100, '(%)')\n",
    "print('1 : ', one, ', 비율 : ', (one / (1 if one+zero == 0 else one+zero)) * 100, '(%)', end='\\n\\n')\n",
    "\n",
    "print('============ predict 0 =============')\n",
    "print('총 횟수 : ', d_ac+ d_fl, ',  타겟기준 : ', fl_crit)\n",
    "print('실제 0 : ', d_ac)\n",
    "print('실제 1 : ', d_fl)\n",
    "print('정답비율 : ', (d_ac / (1 if d_ac+d_fl == 0 else d_ac+d_fl)) * 100, '(%)', end='\\n\\n')\n",
    "    \n",
    "print('============ predict 1 =============')\n",
    "print('총 횟수 : ', ac+ fl, ', 타겟기준 : ', suc_crit)\n",
    "print('실제 1 : ', ac)\n",
    "print('실제 0 : ', fl)\n",
    "print('정답비율 : ', (ac / (1 if ac+fl == 0 else ac+fl)) * 100, '(%)', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cb8e0ba-df9a-4762-a60b-ade92bd7fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST = 0\n",
    "ACC = 1\n",
    "LOSS = 2\n",
    "\n",
    "n_put = LAST\n",
    "load_selection_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea1b5f79-3279-4a5c-84b3-0c0d09986a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_put == LAST :\n",
    "    load_selection_name = call_back_last_filename\n",
    "elif n_put == ACC:\n",
    "    load_selection_name = call_back_acc_max_filename\n",
    "elif n_put == LOSS:\n",
    "    load_selection_name = call_back_loss_min_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c024b605-5044-4e79-a9eb-9ebf5157f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./model_tmp/assets\n",
      "put scale to  Test_Robust_last.onnx  ends\n"
     ]
    }
   ],
   "source": [
    "# h5 to pb\n",
    "\n",
    "model_convert = tf.keras.models.load_model(checkpoint_path + load_selection_name + h5, compile=False)\n",
    "model_convert.save(h5_path + load_selection_name + h5)\n",
    "model_convert.save(tmp_model_path, save_format=\"tf\")\n",
    "\n",
    "# pb to onnx \n",
    "import os\n",
    "os.system('python -m tf2onnx.convert --saved-model ' +  tmp_model_path + ' --output ' + onnx_path + load_selection_name + onnx + ' --opset 13')\n",
    "\n",
    "metadata = db.MetaData()\n",
    "table = db.Table('scaleDatasDict', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "WriteScaleData(table=table, feature_names=feature_names_102, scale_method=scale_method,\n",
    " model_name=load_selection_name + onnx, pandas_data=br[feature_names_102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018ef0d-c74d-49a2-ae99-c6aad87e79c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3299149-dc84-49d9-b964-efb2ed6a5894",
   "metadata": {},
   "source": [
    "# 수동 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f5a73-439d-4e84-830a-52ee43499b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트?? 단순히 테스트하는 곳임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f43b57-0735-4212-b743-133f585d357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = br2[\n",
    "   feature_names_102\n",
    "]\n",
    "\n",
    "y2= br2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33e6a5-f805-4975-b9f1-53c1393a91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_method2 = ROBUST\n",
    "X2 = fitMyScaler(X2, scale_method2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46e815-9ac4-48eb-b7b0-101ad48a4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X2 \n",
    "y_test = y2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508f624-d745-4a0c-b019-8c758f0cc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_h5_path = './h5/'\n",
    "t_model_name = ['fProfit_10_Robust_100_c', 'fProfit_10_Robust_c','fProfit_10_Droupout2','fProfit_10_Robust_c_reuse', 'checkpoint-standard-400-100-loss-min']\n",
    "t_save_model_name = [name + '.h5' for  name in t_model_name]\n",
    "\n",
    "models = []\n",
    "for i in t_save_model_name:\n",
    "    model_tmp = tf.keras.models.load_model(t_h5_path + i, compile=False)\n",
    "    models.append( model_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa251a32-886f-449a-b8fb-bc974d0e03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = models[0].predict(X_test)\n",
    "y_pred2 = models[1].predict(X_test)\n",
    "y_pred3 = models[2].predict(X_test)\n",
    "y_pred4 = models[3].predict(X_test)\n",
    "y_pred5 = models[4].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea185c-7622-4d21-9d88-5c5f77943c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "ac = 0\n",
    "fl = 0\n",
    "d_ac = 0\n",
    "d_fl = 0\n",
    "\n",
    "suc_crit = 0.7\n",
    "fl_crit = 0.5\n",
    "\n",
    "len_y = y_test.shape[0]\n",
    "y_pred = [y_pred1, y_pred2, y_pred3, y_pred4, y_pred5]\n",
    "\n",
    "suc_ratio = 0.6\n",
    "suc_line = int(len(y_pred) * suc_ratio)\n",
    "\n",
    "fail_ratio = 1.0\n",
    "fail_line = int(len(y_pred) * fail_ratio)\n",
    "\n",
    "for i in range(len_y):\n",
    "    if(y_test[i] == 1.0):\n",
    "        one += 1\n",
    "    elif(y_test[i] == 0.0):\n",
    "        zero += 1\n",
    "        \n",
    "    # PREDICT 0\n",
    "    pass_0 = False\n",
    "    pass_0_check = 0 \n",
    "    for pred in y_pred:\n",
    "        if pred[i][0] < fl_crit :\n",
    "            pass_0_check += 1\n",
    "            \n",
    "    if pass_0_check >= fail_line:\n",
    "        pass_0 = True\n",
    "            \n",
    "    if pass_0: \n",
    "        if(y_test[i] == 0.0):\n",
    "            d_ac += 1\n",
    "        else:\n",
    "            d_fl += 1\n",
    "    \n",
    "    # PREDICT 1\n",
    "    pass_1 = False\n",
    "    pass_1_check = 0 \n",
    "    for pred in y_pred:\n",
    "        if pred[i][0] > suc_crit :\n",
    "            pass_1_check += 1\n",
    "            \n",
    "    if pass_1_check >= suc_line:\n",
    "        pass_1 = True\n",
    "            \n",
    "    if pass_1: \n",
    "        if(y_test[i] == 1.0):\n",
    "            ac += 1\n",
    "        else:\n",
    "            fl += 1\n",
    "\n",
    "   \n",
    "    \n",
    "print('기준명 : ', target_col_name, ', 기준값 : ', crit)\n",
    "print('총량 : ', one+zero)\n",
    "print('0 : ', zero, ', 비율 : ', (zero / (1 if one+zero == 0 else one+zero)) * 100, '(%)')\n",
    "print('1 : ', one, ', 비율 : ', (one / (1 if one+zero == 0 else one+zero)) * 100, '(%)', end='\\n\\n')\n",
    "\n",
    "print('============ predict 0 =============')\n",
    "print('총 횟수 : ', d_ac+ d_fl, ',  타겟기준 : ', fl_crit)\n",
    "print('실제 0 : ', d_ac)\n",
    "print('실제 1 : ', d_fl)\n",
    "print('정답비율 : ', (d_ac / (1 if d_ac+d_fl == 0 else d_ac+d_fl)) * 100, '(%)', end='\\n\\n')\n",
    "    \n",
    "print('============ predict 1 =============')\n",
    "print('총 횟수 : ', ac+ fl, ', 타겟기준 : ', suc_crit)\n",
    "print('실제 1 : ', ac)\n",
    "print('실제 0 : ', fl)\n",
    "print('정답비율 : ', (ac / (1 if ac+fl == 0 else ac+fl)) * 100, '(%)', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59d9c8-ec96-417b-a1f9-00f687ce96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0\n",
    "]\n",
    "p = pd.DataFrame(li).T\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f484c-637b-495e-843b-20493c35b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = fitMyScaler(p, ROBUST)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffb44e-232c-4c10-89f8-552c63211f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf2ea0-0c42-417c-858a-6fa50c841961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
