{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6e663b-eb93-4ebb-9fbb-4c3eba485bdc",
   "metadata": {},
   "source": [
    "# 데이터 획득 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b990c0fc-a349-4d91-a368-f5d2724d69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc24889c-cf5c-4f89-b1f7-407161d64f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql://sbe03253:jin94099@database-2.clmg3ftdxi2a.ap-northeast-2.rds.amazonaws.com/MJTradierDB')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8801b92f-451c-4356-8ace-75599e939d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = pd.read_sql_table('buyReports', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6608fa50-6218-4185-ae8c-f388886a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "br = br[( br['isAllBuyed'] == 1) & ( br['isAllSelled'] == 1) & (br['nBuyVolume'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e94819-45cb-4aa1-839f-5b7efa098597",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names =  [   \n",
    "        'nBuyStrategyIdx',\n",
    "        'nRqTime' , \n",
    "        'fStartGap' ,\n",
    "        'fPowerWithOutGap' , \n",
    "        'fPower' , \n",
    "        'fPlusCnt07' , \n",
    "        'fMinusCnt07' , \n",
    "        'fPlusCnt09' , \n",
    "        'fMinusCnt09' ,\n",
    "        'fPowerJar' , \n",
    "        'fOnlyDownPowerJar' , \n",
    "        'fOnlyUpPowerJar' , \n",
    "        'nTradeCnt' , \n",
    "        'nChegyulCnt' , \n",
    "        'nHogaCnt' , \n",
    "        'nNoMoveCnt' , \n",
    "        'nFewSpeedCnt' ,\n",
    "        'nMissCnt' , \n",
    "        'lTotalTradeVolume' , \n",
    "        'lTotalBuyVolume' , \n",
    "        'lTotalSellVolume' ,\n",
    "        'nAccumUpDownCount' ,\n",
    "        'fAccumUpPower' , \n",
    "        'fAccumDownPower' ,\n",
    "        'lTotalTradePrice' , \n",
    "        'lTotalBuyPrice' , \n",
    "        'lTotalSellPrice' , \n",
    "        'lMarketCap' , \n",
    "        'nAccumCountRanking' , \n",
    "        'nMarketCapRanking' , \n",
    "        'nPowerRanking' , \n",
    "        'nTotalBuyPriceRanking' , \n",
    "        'nTotalBuyVolumeRanking' ,\n",
    "        'nTotalTradePriceRanking' ,\n",
    "        'nTotalTradeVolumeRanking' ,\n",
    "        'nTotalRank' , \n",
    "        'nMinuteTotalRank' , \n",
    "        'nMinuteTradePriceRanking' ,\n",
    "        'nMinuteTradeVolumeRanking' , \n",
    "        'nMinuteBuyPriceRanking' , \n",
    "        'nMinuteBuyVolumeRanking' ,\n",
    "        'nMinutePowerRanking' , \n",
    "        'nMinuteCountRanking' ,\n",
    "        'nMinuteUpDownRanking' ,\n",
    "        'nFakeBuyCnt' , \n",
    "        'nFakeAssistantCnt' ,\n",
    "        'nFakeResistCnt' , \n",
    "        'nPriceUpCnt' , \n",
    "        'nPriceDownCnt' ,\n",
    "        'nTotalFakeCnt' ,\n",
    "        'nTotalFakeMinuteCnt' ,\n",
    "        'nUpCandleCnt' , \n",
    "        'nDownCandleCnt' ,\n",
    "        'nUpTailCnt' , \n",
    "        'nDownTailCnt' ,\n",
    "        'nShootingCnt' ,\n",
    "        'nCandleTwoOverRealCnt' ,\n",
    "        'nCandleTwoOverRealNoLeafCnt' , \n",
    "        'fSpeedCur' , \n",
    "        'fHogaSpeedCur' ,\n",
    "        'fTradeCur' , \n",
    "        'fPureTradeCur' , \n",
    "        'fPureBuyCur' , \n",
    "        'fHogaRatioCur' ,  \n",
    "        'fSharePerHoga' , \n",
    "        'fSharePerTrade' ,\n",
    "        'fHogaPerTrade' , \n",
    "        'fTradePerPure' , \n",
    "        'fMaDownFsVal' , \n",
    "        'fMa20mVal' , \n",
    "        'fMa1hVal' ,\n",
    "        'fMa2hVal' ,\n",
    "        'fMaxMaDownFsVal' ,\n",
    "        'fMaxMa20mVal' ,\n",
    "        'fMaxMa1hVal' ,\n",
    "        'fMaxMa2hVal' ,\n",
    "        'nMaxMaDownFsTime' ,\n",
    "        'nMaxMa20mTime' ,\n",
    "        'nMaxMa1hTime' ,\n",
    "        'nMaxMa2hTime' ,\n",
    "        'nDownCntMa20m' ,\n",
    "        'nDownCntMa1h' ,\n",
    "        'nDownCntMa2h' ,\n",
    "        'nUpCntMa20m' ,\n",
    "        'nUpCntMa1h' ,\n",
    "        'nUpCntMa2h' ,\n",
    "        'fMSlope' ,\n",
    "        'fISlope' ,\n",
    "        'fTSlope' ,\n",
    "        'fHSlope' ,\n",
    "        'fRSlope' ,\n",
    "        'fDSlope' ,\n",
    "        'fMAngle' ,\n",
    "        'fIAngle' ,\n",
    "        'fTAngle' ,\n",
    "        'fHAngle' ,\n",
    "        'fRAngle' ,\n",
    "        'fDAngle' ,\n",
    "        'nCrushCnt' ,\n",
    "        'nCrushUpCnt' ,\n",
    "        'nCrushDownCnt' ,\n",
    "        'nCrushSpecialDownCnt' \n",
    "]\n",
    "feature_size = len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f47e039-04cf-4368-b596-9ed7f16284e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float32범위보다 높은 double값이 있어 inf로 계산됨 \n",
    "# 오류발생 가능성이 있어 값의 상한선을 둠\n",
    "BILLION = 1000000000\n",
    "br.loc[ br['fSharePerHoga'] > BILLION, 'fSharePerHoga'] = BILLION \n",
    "br.loc[ br['fHogaPerTrade'] > BILLION, 'fHogaPerTrade'] = BILLION\n",
    "br.loc[ br['fSharePerTrade'] > BILLION, 'fSharePerTrade'] = BILLION\n",
    "br.loc[ br['fTradePerPure'] > BILLION, 'fTradePerPure'] = BILLION\n",
    "\n",
    "\n",
    "X = br[\n",
    "   feature_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059cc8a0-9177-42be-a15b-889698cd9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_s = None\n",
    "max_s = None\n",
    "mean_s = None\n",
    "std_s = None\n",
    "zero_s = None\n",
    "median_s = None\n",
    "iqr3_s = None\n",
    "iqr1_s = None\n",
    "\n",
    "MINMAX = 'MinMax'\n",
    "ROBUST = 'Robust'\n",
    "STANDARD = 'Standard'\n",
    "\n",
    "def setScaler(p_data):\n",
    "    np_data = p_data.to_numpy(dtype=np.float32)\n",
    "\n",
    "    row_num = np_data.shape[0]\n",
    "    col_num = np_data.shape[1]\n",
    "    \n",
    "    # global 사용\n",
    "    global min_s\n",
    "    global max_s\n",
    "    global mean_s\n",
    "    global std_s\n",
    "    global zero_s\n",
    "    global median_s\n",
    "    global iqr3_s\n",
    "    global iqr1_s\n",
    "    \n",
    "    # MinMaxScaler\n",
    "    min_s = np_data.min(axis=0)\n",
    "    max_s = np_data.max(axis=0)\n",
    "    \n",
    "    # StandardScaler\n",
    "    mean_s = np_data.mean(axis=0)\n",
    "    std_s = np_data.std(axis=0)\n",
    "    zero_s = np.zeros(col_num, dtype=np.float32)\n",
    "    \n",
    "    # RobustScaler\n",
    "    median_s = np.median(np_data, axis=0)\n",
    "    iqr3_s = np.quantile(np_data, q=0.75, axis=0)\n",
    "    iqr1_s = np.quantile(np_data, q=0.25, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6ae520-79ff-41e4-a518-db4d6a39ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "setScaler(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8908757d-1014-48a1-a8d2-eea9ca094a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitMyScaler(p_data, scale_method='MinMax'):\n",
    "    np_data = p_data.to_numpy(dtype=np.float32)\n",
    "\n",
    "    row_num = np_data.shape[0]\n",
    "    col_num = np_data.shape[1]\n",
    "    \n",
    "    d0_s = None\n",
    "    d1_s = None\n",
    "    d2_s = None\n",
    "    \n",
    "    if scale_method == 'MinMax':\n",
    "        d0_s = min_s\n",
    "        d1_s = max_s\n",
    "        d2_s = min_s\n",
    "    elif scale_method == 'Standard':\n",
    "        d0_s = mean_s\n",
    "        d1_s = std_s\n",
    "        d2_s = zero_s\n",
    "    elif scale_method == 'Robust':\n",
    "        d0_s = median_s\n",
    "        d1_s = iqr3_s\n",
    "        d2_s = iqr1_s\n",
    "    else :\n",
    "        print('해당하는 스케일함수가 없습니다.')\n",
    "        return\n",
    "    \n",
    "    for i in range(col_num):\n",
    "        \n",
    "        d0 = d0_s[i]\n",
    "        d1 = d1_s[i]\n",
    "        d2 = d2_s[i]\n",
    "        \n",
    "        denom = d1 - d2\n",
    "        if denom == 0:\n",
    "            denom = max_s[i] - min_s[i]\n",
    "            if denom == 0 or np.isinf(denom) or np.isnan(denom):\n",
    "                denom = 1\n",
    "                \n",
    "        for j in range(row_num):\n",
    "            np_data[j, i] = (np_data[j, i] - d0) / denom\n",
    "            \n",
    "            \n",
    "    return np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44f7588-0a25-40af-8488-d6e15f292e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteScaleData(table, feature_names, scale_method, model_name, pandas_data ):\n",
    "    try:\n",
    "        today = datetime.datetime.today()\n",
    "        scaleMethod = scale_method\n",
    "        sModel = model_name\n",
    "        \n",
    "        np_data = pandas_data.to_numpy(dtype=np.float32)\n",
    "        row_num = np_data.shape[0]\n",
    "        col_num = np_data.shape[1]\n",
    "        \n",
    "        d0_s = None\n",
    "        d1_s = None\n",
    "        d2_s = None\n",
    "    \n",
    "        if scale_method == 'MinMax':\n",
    "            d0_s = min_s\n",
    "            d1_s = max_s\n",
    "            d2_s = min_s\n",
    "        elif scale_method == 'Standard':\n",
    "            d0_s = mean_s\n",
    "            d1_s = std_s\n",
    "            d2_s = zero_s\n",
    "        elif scale_method == 'Robust':\n",
    "            d0_s = median_s\n",
    "            d1_s = iqr3_s\n",
    "            d2_s = iqr1_s\n",
    "        else :\n",
    "            print('해당하는 스케일함수가 없습니다.')\n",
    "            return\n",
    "        \n",
    "        \n",
    "        for idx, col in enumerate(feature_names):\n",
    "            sVar = col\n",
    "            \n",
    "            d0 = d0_s[idx]\n",
    "            d1 = d1_s[idx]\n",
    "            d2 = d2_s[idx]\n",
    "            \n",
    "            if d2 - d1 == 0:\n",
    "                d1 = max_s[idx]\n",
    "                d2 = min_s[idx]\n",
    "            \n",
    "            query = db.insert(table).values( {'dTime': today, 'sScaleMethod':scaleMethod, 'sVariableName':sVar, \n",
    "                            'sModelName':sModel, 'fD0':d0, 'fD1':d1, 'fD2':d2, 'nSeq':idx})\n",
    "            result_proxy = conn.execute(query)\n",
    "            result_proxy.close()\n",
    "        print('put scale to ', sModel, ' ends')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239ef22f-bf89-42c3-8db0-3f432d2e6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-0.6666667   0.00702056 -0.21732403 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.8333333   1.355267   -0.6782613  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.8194444   1.3582475  -0.6782613  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.41666666  1.331258    0.37462762 ...  2.          0.\n",
      "   0.        ]\n",
      " [ 0.43055555  1.3345697   0.37462762 ...  2.          0.\n",
      "   0.        ]\n",
      " [ 0.44444445  1.3345697   0.37462762 ...  2.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "scale_method = ROBUST\n",
    "X = fitMyScaler(X, scale_method)\n",
    "\n",
    "print(type(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bb68695-532f-44eb-8d3f-873845f84229",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = 0.01\n",
    "\n",
    "br.loc[br['fProfit'] >= crit, 'target'] = 1\n",
    "br.loc[br['fProfit'] < crit, 'target'] = 0\n",
    "y = br['target']\n",
    "\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5119f085-84a3-4e90-9cc4-2a9964de168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6000502c-5725-4cb7-9af1-d241e0c03ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = int(1 / (random.random() + 0.00000001) * 100)\n",
    "random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8010c47-713d-47e8-a665-9bc814c1c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98022fe4-374b-472c-b543-c1064dc11c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (50620, 102)\n",
      "y_train :  (50620,)\n",
      "X_test  :  (16874, 102)\n",
      "y_test  :  (16874,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train : ', X_train.shape)\n",
    "print('y_train : ', y_train.shape)\n",
    "print('X_test  : ', X_test.shape)\n",
    "print('y_test  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34dbe567-cf95-4ee3-9978-57ac87f12f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputDim = feature_size\n",
    "nOutputDim = 1\n",
    "main_input = Input(shape=(nInputDim), name='input')\n",
    "x = Dense(1024, activation='relu')(main_input)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Classification\n",
    "main_output = Dense(nOutputDim, activation='sigmoid', name='output')(x)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=main_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e3faa-5870-4f20-91d1-ff04dcdd4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch Normalization - Activation - Dropout  순서\n",
    "# nInputDim = feature_size\n",
    "# nOutputDim = 1\n",
    "\n",
    "# main_input = Input(shape=(nInputDim), name='input')\n",
    "# x = Dense(256, activation='relu')(main_input)\n",
    "\n",
    "# x = Dense(256)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(.2)(x)\n",
    "\n",
    "# x = Dense(512)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(.2)(x)\n",
    "\n",
    "# x = Dense(512)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(.2)(x)\n",
    "\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# # Classification\n",
    "# main_output = Dense(nOutputDim, activation='sigmoid', name='output')(x)\n",
    "\n",
    "# model = Model(inputs=main_input, outputs=main_output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6123610-16c0-471a-be51-1ea74b6fe506",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5b93ee2972e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c91f770e-c62b-4e7a-a0be-f6b70f621b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-03990686ab1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('accuracy : ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe6726e-720b-4401-bfbd-0e8c61d46145",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f2ee67-1520-450a-aea0-fb011875e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0 =============\n",
      "d_sum :  16770\n",
      "d_   13034  and  3736\n",
      "d_ratio :  0.7772212283840191\n",
      "\n",
      "============ 1 =============\n",
      "sum :  104\n",
      "14  and  90\n",
      "ratio :  0.1346153846153846\n"
     ]
    }
   ],
   "source": [
    "ac = 0\n",
    "fl = 0\n",
    "\n",
    "d_ac = 0\n",
    "d_fl = 0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_pred[i] > 0.85:\n",
    "        if(y_test[i] == 1.0):\n",
    "            ac += 1\n",
    "        else:\n",
    "            fl += 1\n",
    "            \n",
    "    if y_pred[i] < 0.9:\n",
    "        if(y_test[i] == 0.0):\n",
    "            d_ac += 1\n",
    "        else:\n",
    "            d_fl += 1\n",
    "    #print(i, '  pred : ' , y_pred[i], ' test : ' , y_test[i])\n",
    "\n",
    "print('============ 0 =============')\n",
    "print('d_sum : ', d_ac+ d_fl)\n",
    "print('d_  ', d_ac, ' and ', d_fl)\n",
    "print('d_ratio : ', d_ac / (d_ac+d_fl), end='\\n\\n')\n",
    "    \n",
    "print('============ 1 =============')\n",
    "print('sum : ', ac+ fl)\n",
    "print(ac, ' and ', fl)\n",
    "print('ratio : ', ac / (ac+fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea1b5f79-3279-4a5c-84b3-0c0d09986a5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2464d2bfd794>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0moutput_onnx_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.onnx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msave_model_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# h5 to pb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# onnx 생성 및 스케일 DB 삽입\n",
    "\n",
    "model_name = 'fProfit_10_Robust_100_c'\n",
    "h5_path = './h5/'\n",
    "onnx_path = './onnx/'\n",
    "tmp_model_path = './model_tmp/'\n",
    "save_model_name = model_name +'.h5'\n",
    "output_onnx_file_name = model_name + '.onnx'\n",
    "\n",
    "model.save(h5_path + save_model_name)\n",
    "\n",
    "# h5 to pb\n",
    "model_convert = tf.keras.models.load_model(h5_path + save_model_name, compile=False)\n",
    "model_convert.save(tmp_model_path, save_format=\"tf\")\n",
    "\n",
    "# pb to onnx \n",
    "import os\n",
    "os.system('python -m tf2onnx.convert --saved-model ' +  tmp_model_path + ' --output ' + onnx_path + output_onnx_file_name + ' --opset 13')\n",
    "\n",
    "metadata = db.MetaData()\n",
    "table = db.Table('scaleDatasDict', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "WriteScaleData(table=table, feature_names=feature_names, scale_method=scale_method,\n",
    " model_name=output_onnx_file_name, pandas_data=br[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018ef0d-c74d-49a2-ae99-c6aad87e79c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f424225-98c3-4d9c-b758-d99922d208c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f5a73-439d-4e84-830a-52ee43499b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 테스트??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59d9c8-ec96-417b-a1f9-00f687ce96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,0,0,0,\n",
    "    0,0\n",
    "]\n",
    "p = pd.DataFrame(li).T\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f484c-637b-495e-843b-20493c35b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = fitMyScaler(p, 'Robust')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffb44e-232c-4c10-89f8-552c63211f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
