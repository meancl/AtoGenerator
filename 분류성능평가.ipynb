{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import load_model\n",
    "import gc\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "from mylib.featurenames import *\n",
    "from mylib.cleaner import *\n",
    "from mylib.scaler import *\n",
    "from mylib.ftploader import *\n",
    "from mylib.modelpostfix import *\n",
    "from mylib.tester import *\n",
    "from mylib.server_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12366587035919065121\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "\n",
    "engine = create_engine(mysql_server_uri)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get db data '''\n",
    "br_full_data = pd.read_sql_table('buyreports', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' db data filter '''\n",
    "get_filter = ( br_full_data['isAllBuyed'] == 1) & ( br_full_data['isAllSelled'] == 1) & (br_full_data['dTradeTime'] >= '2023-02-24')\n",
    "br = br_full_data[get_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get features name'''\n",
    "feature_names =  f_name_102\n",
    "feature_size = len(feature_names)\n",
    "\n",
    "''' set X data '''\n",
    "X = br[feature_names].to_numpy(dtype=np.float64)\n",
    "\n",
    "''' set y data '''\n",
    "y_condition = (br['fMaxPowerAfterBuyWhile30'] < 0.025)\n",
    "y = np.where(y_condition, 1, 0)\n",
    "\n",
    "y_test =y\n",
    "y_predict = []\n",
    "\n",
    "modelTester = ModelTester(engine, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트할 모델\n",
    "\n",
    "dnn_model_names = []\n",
    "\n",
    "rf_model_names = ['rf_maxM_d3_v1', 'rf_maxM_d3_v2', 'rf_maxM_d2_v2', 'rf_maxM_d45_v2', 'rf_max30_d4_v2']\n",
    "#['rf_max30_d3', 'rf_max30_d4', 'rf_max30_d5', 'rf_max30_d3_v2', 'rf_maxM_d3']\n",
    "#['rf_s94_2000_6_v1', 'rf_s13_2000_6_v1', 'rf_s13(15_2000_6_v1', \n",
    "#'rf_pmd15_2000_6_v1', 'rf_pow30_01_2000_6_v1', 'rf_prf_01_2000_6_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp= FtpLoader(ftp_ip, ftp_port, ftp_id, ftp_pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, mn in enumerate(dnn_model_names):\n",
    "    ftp.download(mn + h5_, h5_path, '/h5/')\n",
    "    x_datas = modelTester.setFullScale(X, mn+onnx_)\n",
    "\n",
    "    h5_model = load_model(h5_path + mn + h5_)\n",
    "\n",
    "    pred = h5_model.predict(x_datas)\n",
    "    y_predict.append(pred)\n",
    "    \n",
    "    del h5_model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, mn in enumerate(rf_model_names):\n",
    "    ftp.download(mn+onnx_, onnx_path, '/onnx/')\n",
    "    \n",
    "    x_datas = X\n",
    "\n",
    "    # onnx_model = onnx.load(onnx_path + mn + onnx_)\n",
    "    sess = rt.InferenceSession(onnx_path + mn + onnx_)\n",
    "    res = sess.run(['output'],{'input': x_datas})\n",
    "    y_predict.append(res[0])\n",
    "    \n",
    "    del sess\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총량 :  48862\n",
      "0 :  14631 , 비율 :  29.94351438745856 (%)\n",
      "1 :  34231 , 비율 :  70.05648561254144 (%)\n",
      "\n",
      "============ predict 0 =============\n",
      "총 횟수 :  3556 ,  타겟기준 :  0.0\n",
      "실제 0 :  2166\n",
      "실제 1 :  1390\n",
      "정답비율 :  60.91113610798649 (%)\n",
      "\n",
      "============ predict 1 =============\n",
      "총 횟수 :  45306 , 타겟기준 :  1.0\n",
      "실제 1 :  32841\n",
      "실제 0 :  12465\n",
      "정답비율 :  72.48708780294001 (%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "############## test #############\n",
    "from mylib.tester import *\n",
    "# suc_crit = 0.8 # 1이라 판정할 값의 기준\n",
    "# fl_crit = 0.5  # 0이라 판정할 값의 기준\n",
    "\n",
    "suc_ratio = 0.65 # 모델들에서 1이라 종합할 비율\n",
    "fail_ratio = 0.65 # 모델들에서 0이라 종합할 비율\n",
    "\n",
    "testClassification(y_test, y_predict, suc_pass_ratio=suc_ratio, fail_pass_ratio=fail_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeTestData(onnx_list=rf_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
