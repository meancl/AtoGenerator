{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "\n",
    "from mylib.featurenames import *\n",
    "from mylib.cleaner import *\n",
    "from mylib.randomer import *\n",
    "from mylib.server_info import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgb = LGBMClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "cat = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(mysql_server_uri)\n",
    "conn = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get db data '''\n",
    "br_full_data = pd.read_sql_table('buyreports', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' db data filter '''\n",
    "get_filter = ( br_full_data['isAllBuyed'] == 1) & ( br_full_data['isAllSelled'] == 1)\n",
    "br = br_full_data[get_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get features name'''\n",
    "feature_names =  f_name_102\n",
    "feature_size = len(feature_names)\n",
    "\n",
    "''' set X data '''\n",
    "X = br[feature_names].to_numpy(dtype=np.float64)\n",
    "\n",
    "''' set y data '''\n",
    "y_condition = (br['fMaxPowerAfterBuyWhile30'] < 0.03)\n",
    "y = np.where(y_condition, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' make random seed '''\n",
    "random_seed = getRandomSeed()\n",
    "\n",
    "''' split train test validation data '''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "param_rf ={\n",
    "    'n_estimators':[100, 200], #, 400, 600],\n",
    "    'max_depth':[6], #,8,10,12],\n",
    "    # 'min_samples_leaf':[8,12,18],\n",
    "    # 'min_samples_split':[8,16,20]\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_xgb = {\"max_depth\": [10,30,50],\n",
    "              \"min_child_weight\" : [1,3,6,10],\n",
    "              \"n_estimators\": [200,300,500,1000]\n",
    "              }    \n",
    "# LGB                        \n",
    "param_lgb = {\"learning_rate\" : [0.01,0.1,0.2,0.3,0.4,0.5],\n",
    "             \"max_depth\" : [25, 50, 75],\n",
    "             \"num_leaves\" : [100,300,500,900,1200],\n",
    "             \"n_estimators\" : [100, 200, 300,500,800,1000],\n",
    "             \"learning_rate\" : [0.01,0.1,0.2,0.3,0.4,0.5]\n",
    "              }\n",
    "# GBM              \n",
    "param_gbm = {\"max_depth\" : [4,5,6,7,8,9,10],\n",
    "             \"learning_rate\" : [0.01,0.1,0.2,0.3,0.4,0.5],\n",
    "             \"n_estimators\" : [100,200,300,500]\n",
    "              }\n",
    "# CAT\n",
    "param_cat = {\"depth\" : [6,4,5,7,8,9,10],\n",
    "          \"iterations\" : [250,100,500,1000],\n",
    "          \"learning_rate\" : [0.001,0.01,0.1,0.2,0.3], \n",
    "          \"l2_leaf_reg\" : [2,5,10,20,30],\n",
    "          \"border_count\" : [254]\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy','f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_rf = GridSearchCV (estimator = rf, param_grid = param_rf, scoring =scoring, cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "# gscv_xgb = GridSearchCV (estimator = xgb, param_grid = param_xgb, scoring =scoring, cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "# gscv_lgb = GridSearchCV (estimator = lgb, param_grid = param_lgb, scoring =scoring, cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "# gscv_gbm = GridSearchCV (estimator = gbm, param_grid = param_gbm, scoring =scoring, cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "# gscv_cat = GridSearchCV (estimator = cat, param_grid = param_cat, scoring =scoring, cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "\n",
    "gscv_rf.fit(trainX, trainY)\n",
    "# gscv_xgb.fit(trainX, trainY)\n",
    "# gscv_lgb.fit(trainX, trainY)\n",
    "# gscv_gbm.fit(trainX, trainY)\n",
    "# gscv_cat.fit(trainX, trainY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
